"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1548],{3905:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>m});var a=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var s=a.createContext({}),c=function(e){var t=a.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},p=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},g=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),g=c(r),m=n,b=g["".concat(s,".").concat(m)]||g[m]||u[m]||i;return r?a.createElement(b,o(o({ref:t},p),{},{components:r})):a.createElement(b,o({ref:t},p))}));function m(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,o=new Array(i);o[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:n,o[1]=l;for(var c=2;c<i;c++)o[c]=r[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,r)}g.displayName="MDXCreateElement"},8550:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var a=r(7462),n=(r(7294),r(3905));const i={slug:"travis",title:"TrAVis - Transformer Attention Visualiser",description:"How we created an in-browser BERT attention visualiser without a server",authors:["nixie","ayaka"],tags:["nlp","ai","deeplearning","machinelearning","pyodide","d3.js","bert","huggingface","tokeniser","jax","transformer"]},o=void 0,l={permalink:"/blog/travis",source:"@site/blog/2022-09-28-travis/index.md",title:"TrAVis - Transformer Attention Visualiser",description:"How we created an in-browser BERT attention visualiser without a server",date:"2022-09-28T00:00:00.000Z",formattedDate:"September 28, 2022",tags:[{label:"nlp",permalink:"/blog/tags/nlp"},{label:"ai",permalink:"/blog/tags/ai"},{label:"deeplearning",permalink:"/blog/tags/deeplearning"},{label:"machinelearning",permalink:"/blog/tags/machinelearning"},{label:"pyodide",permalink:"/blog/tags/pyodide"},{label:"d3.js",permalink:"/blog/tags/d-3-js"},{label:"bert",permalink:"/blog/tags/bert"},{label:"huggingface",permalink:"/blog/tags/huggingface"},{label:"tokeniser",permalink:"/blog/tags/tokeniser"},{label:"jax",permalink:"/blog/tags/jax"},{label:"transformer",permalink:"/blog/tags/transformer"}],readingTime:2.465,hasTruncateMarker:!0,authors:[{name:"Jing Hua",title:"Open source princess",url:"https://github.com/ztjhz",imageURL:"https://github.com/ztjhz.png",key:"nixie"},{name:"Ayaka",title:"A 23-year-old computer science artist dedicated to NLP",url:"https://github.com/ayaka14732",imageURL:"https://github.com/ayaka14732.png",key:"ayaka"}],frontMatter:{slug:"travis",title:"TrAVis - Transformer Attention Visualiser",description:"How we created an in-browser BERT attention visualiser without a server",authors:["nixie","ayaka"],tags:["nlp","ai","deeplearning","machinelearning","pyodide","d3.js","bert","huggingface","tokeniser","jax","transformer"]},prevItem:{title:"ByteVid - Deep Learning Hackathon 1st Place",permalink:"/blog/bytevid"}},s={authorsImageUrls:[void 0,void 0]},c=[{value:"What is this?",id:"what-is-this",level:2}],p={toc:c};function u(e){let{components:t,...i}=e;return(0,n.kt)("wrapper",(0,a.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Result",src:r(3588).Z,width:"1488",height:"991"})),(0,n.kt)("p",null,"How we created an in-browser BERT attention visualiser without a server"),(0,n.kt)("h2",{id:"what-is-this"},"What is this?"),(0,n.kt)("p",null,"TrAVis is a Transformer Attention Visualiser. The idea of visualising the attention matrices is inspired by ",(0,n.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/1409.0473"},"Neural Machine Translation by Jointly Learning to Align and Translate"),"."))}u.isMDXComponent=!0},3588:(e,t,r)=>{r.d(t,{Z:()=>a});const a=r.p+"assets/images/result-d51c7e47c5c036d4ae94a4833adc2efe.png"}}]);